{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65c44216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import requests\n",
    "\n",
    "# Download the stormevents databases\n",
    "BRONZE_PATH = '/usr/datalake/bronze/stormevents'\n",
    "SILVER_PATH = '/usr/datalake/silver/stormevents'\n",
    "NCEI_URL = 'https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles'\n",
    "\n",
    "CSV_FILENAME = f'{SILVER_PATH}/docs/csvfiles.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c22a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{BRONZE_PATH}/csvfiles', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9039d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>year</th>\n",
       "      <th>updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StormEvents_details-ftp_v1.0_d1950_c20250520.c...</td>\n",
       "      <td>1950</td>\n",
       "      <td>2025-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StormEvents_details-ftp_v1.0_d1951_c20250520.c...</td>\n",
       "      <td>1951</td>\n",
       "      <td>2025-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StormEvents_details-ftp_v1.0_d1952_c20250520.c...</td>\n",
       "      <td>1952</td>\n",
       "      <td>2025-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StormEvents_details-ftp_v1.0_d1953_c20250520.c...</td>\n",
       "      <td>1953</td>\n",
       "      <td>2025-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StormEvents_details-ftp_v1.0_d1954_c20250520.c...</td>\n",
       "      <td>1954</td>\n",
       "      <td>2025-05-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  year     updated\n",
       "0  StormEvents_details-ftp_v1.0_d1950_c20250520.c...  1950  2025-05-20\n",
       "1  StormEvents_details-ftp_v1.0_d1951_c20250520.c...  1951  2025-05-20\n",
       "2  StormEvents_details-ftp_v1.0_d1952_c20250520.c...  1952  2025-05-20\n",
       "3  StormEvents_details-ftp_v1.0_d1953_c20250520.c...  1953  2025-05-20\n",
       "4  StormEvents_details-ftp_v1.0_d1954_c20250520.c...  1954  2025-05-20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pd.read_csv(CSV_FILENAME)\n",
    "index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75b097bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping StormEvents_details-ftp_v1.0_d1950_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1951_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1952_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1953_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1954_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1955_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1956_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1957_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1958_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1959_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1960_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1961_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1962_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1963_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1964_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1965_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1966_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1967_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1968_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1969_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1970_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1971_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1972_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1973_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1974_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1975_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1976_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1977_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1978_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1979_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1980_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1981_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1982_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1983_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1984_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1985_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1986_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1987_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1988_c20250520.csv.gz. Year earlier than 1990.\n",
      "Skipping StormEvents_details-ftp_v1.0_d1989_c20250520.csv.gz. Year earlier than 1990.\n",
      "Downloaded StormEvents_details-ftp_v1.0_d1990_c20250520.csv.gz.\n",
      "Downloaded StormEvents_details-ftp_v1.0_d1991_c20250520.csv.gz.\n",
      "Downloaded StormEvents_details-ftp_v1.0_d1992_c20250520.csv.gz.\n",
      "Downloaded StormEvents_details-ftp_v1.0_d1993_c20250520.csv.gz.\n",
      "Downloaded StormEvents_details-ftp_v1.0_d1994_c20250520.csv.gz.\n",
      "Downloaded StormEvents_details-ftp_v1.0_d1995_c20250520.csv.gz.\n",
      "Downloaded StormEvents_details-ftp_v1.0_d1996_c20250520.csv.gz.\n",
      "Downloaded StormEvents_details-ftp_v1.0_d1997_c20250520.csv.gz.\n",
      "Downloaded StormEvents_details-ftp_v1.0_d1998_c20250520.csv.gz.\n",
      "Downloaded StormEvents_details-ftp_v1.0_d1999_c20250520.csv.gz.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2000_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2001_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2002_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2003_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2004_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2005_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2006_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2007_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2008_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2009_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2010_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2011_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2012_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2013_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2014_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2015_c20250818.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2016_c20250818.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2017_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2018_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2019_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2020_c20250702.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2021_c20250520.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2022_c20250721.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2023_c20250731.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2024_c20250818.csv.gz. File already exists.\n",
      "Skipping StormEvents_details-ftp_v1.0_d2025_c20250818.csv.gz. File already exists.\n"
     ]
    }
   ],
   "source": [
    "for _, csvfile in index.iterrows():\n",
    "    filename = csvfile['filename']\n",
    "    if csvfile['year'] < 1990:\n",
    "        print(f'Skipping {filename}. Year earlier than 1990.')\n",
    "        continue\n",
    "    \n",
    "    filename_local = f'{BRONZE_PATH}/csvfiles/{filename}'\n",
    "    if os.path.exists(filename_local):\n",
    "        print(f'Skipping {filename}. File already exists.')\n",
    "        continue\n",
    "\n",
    "    pattern = f'{BRONZE_PATH}/csvfiles/{filename[:36]}*.csv.gz'\n",
    "    if len(glob.glob(pattern)):\n",
    "        print(f'WARNING: Found older version of {filename}. Delete the older version.')\n",
    "        continue\n",
    "\n",
    "    url = f'{NCEI_URL}/{filename}'\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with open(filename_local, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    print(f\"Downloaded {filename}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aa11ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olieigra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
