{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33560cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Module, Sequential, Linear, Tanh, MSELoss\n",
    "\n",
    "IGRA_PATH = '/usr/datalake/silver/igra/gph20s10k'\n",
    "STATION_LIST = '/usr/datalake/silver/igra/doc/igra2-station-list.csv'\n",
    "ARTIFACTS_PATH = '/usr/datalake/silver/stormevents/csvfiles/igra_maidenhead'\n",
    "STATION_ID = 'USM00072649'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8256237",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Sequential(\n",
    "            Linear(105, 80),\n",
    "            Tanh(),\n",
    "            Linear(80, 60),\n",
    "            Tanh(),\n",
    "            Linear(60, 40),\n",
    "            Tanh(),\n",
    "            Linear(40, 20)\n",
    "        )\n",
    "\n",
    "        self.decoder = Sequential(\n",
    "            Linear(20, 40),\n",
    "            Tanh(),\n",
    "            Linear(40, 60),\n",
    "            Tanh(),\n",
    "            Linear(60, 80),\n",
    "            Tanh(),\n",
    "            Linear(80, 105)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2073f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class olie_igra_trainer:\n",
    "    batch_size = 256\n",
    "    epochs = 1024\n",
    "    learning_rate = 0.005\n",
    "    learning_rate_gamma = 0.99\n",
    "    lambda_param = .0001\n",
    "\n",
    "    def __init__(self, igra_path: str, artifact_path: str, station_id: str, model):\n",
    "        self.igra_path = igra_path\n",
    "        self.station_id = station_id\n",
    "        self.artifact_path = artifact_path\n",
    "        self.model = model\n",
    "\n",
    "    def load_transform_dataset(self):\n",
    "        X = pd.read_csv(f'{self.igra_path}/{self.station_id}-data-gph20s10k.csv')\n",
    "\n",
    "        # Remove irrelevant data\n",
    "        X = X[X['hour'] == 12]\n",
    "        X = X.drop(['id', 'effective_date', 'hour', 'day_num', '0_gph',\n",
    "                    '1_gph', '2_gph', '3_gph', '4_gph', '5_gph',\n",
    "                    '6_gph', '7_gph', '8_gph', '9_gph', '10_gph',\n",
    "                    '11_gph', '12_gph', '13_gph', '14_gph', '15_gph',\n",
    "                    '16_gph', '17_gph', '18_gph', '19_gph', '20_gph'\n",
    "                    ], axis=1)\n",
    "        \n",
    "        # Scale the X dataset\n",
    "        ss = PowerTransformer()\n",
    "        X = ss.fit_transform(X)\n",
    "\n",
    "        # Save the transform\n",
    "        os.makedirs(self.artifact_path, exist_ok=True)\n",
    "        with open(f'{self.artifact_path}/{self.station_id}_scaler.pkl', 'wb') as f:\n",
    "            pickle.dump(ss, f)\n",
    "        \n",
    "        train, test = train_test_split(X, test_size=0.2)\n",
    "        self.x_train = torch.from_numpy(train).float().cuda()\n",
    "        self.x_test = torch.from_numpy(test).float().cuda()\n",
    "        self.n_batches = self.x_train.size()[0] // self.batch_size\n",
    "\n",
    "        print (f\"Station ID: {self.station_id}, Training size: {self.x_train.size()[0]:,}, Predict size: {self.x_test.size()[0]:,}, Feature count: {self.x_train.size()[1]}, Number of batches: {self.n_batches}\")\n",
    "\n",
    "    def train(self, inputs, labels) -> float:\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Calculate error\n",
    "        logits = self.model(inputs)\n",
    "        cost = self.loss_function(logits, labels)\n",
    "\n",
    "        # Back propagation\n",
    "        cost.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return float(cost.item())\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Calculate error\n",
    "        logits = self.model(inputs).clone().detach()\n",
    "\n",
    "        return logits\n",
    "    \n",
    "    def r2_score_manual(self, preds, target):\n",
    "        target_mean = torch.mean(target)\n",
    "        ss_tot = torch.sum((target - target_mean) ** 2) # Total sum of squares\n",
    "        ss_res = torch.sum((target - preds) ** 2)       # Residual sum of squares\n",
    "        r2 = 1 - (ss_res / ss_tot)\n",
    "        \n",
    "        return float(r2.item())\n",
    "    \n",
    "    def output_progress(self, epoch: int, cost: float):\n",
    "        preds = self.predict(self.x_test)\n",
    "        acc = self.r2_score_manual(self.x_test, preds)\n",
    "        print(f\"Epoch: {epoch+1}, cost: {cost / self.n_batches:.4f}, acc: {acc:.3f}, lr: {self.scheduler.get_last_lr()[0]:.2e}\\r\", end=\"\")\n",
    "        \n",
    "    def train_orch(self):\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), self.learning_rate)\n",
    "        self.loss_function = MSELoss()\n",
    "        self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=self.learning_rate_gamma)\n",
    "    \n",
    "        for epoch in range(self.epochs):\n",
    "            cost = 0\n",
    "            loader = DataLoader(dataset = self.x_train, batch_size = self.batch_size, shuffle = True)\n",
    "\n",
    "            for batch in loader:\n",
    "                cost += self.train(batch, batch)\n",
    "\n",
    "            self.scheduler.step()\n",
    "\n",
    "            if epoch % 32 == 0:\n",
    "                self.output_progress(epoch, cost)\n",
    "        \n",
    "        self.output_progress(epoch, cost)\n",
    "        print()\n",
    "\n",
    "    def save_weights(self):\n",
    "        torch.save(self.model.state_dict(), f'{self.artifact_path}/{self.station_id}_fnn.pt')\n",
    "\n",
    "    def dispose(self):\n",
    "        del self.x_train\n",
    "        del self.x_test\n",
    "        del self.optimizer\n",
    "        del self.loss_function\n",
    "        del self.scheduler\n",
    "        del self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "610544ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_station(station_id: str):\n",
    "    model = AutoEncoder().cuda()\n",
    "    train = olie_igra_trainer(IGRA_PATH, ARTIFACTS_PATH, station_id, model)\n",
    "\n",
    "    train.load_transform_dataset()\n",
    "    train.train_orch()\n",
    "    train.save_weights()\n",
    "    train.dispose()\n",
    "\n",
    "    del train\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6ff110e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>fst_year</th>\n",
       "      <th>lst_year</th>\n",
       "      <th>nobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>BBM00078954</td>\n",
       "      <td>13.0716</td>\n",
       "      <td>-59.4922</td>\n",
       "      <td>56.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GRANTLEY ADAMS</td>\n",
       "      <td>1965</td>\n",
       "      <td>2025</td>\n",
       "      <td>31823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>BDM00078016</td>\n",
       "      <td>32.3669</td>\n",
       "      <td>-64.6772</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L F WADE INTERNATIONAL AIRPORT</td>\n",
       "      <td>1946</td>\n",
       "      <td>2025</td>\n",
       "      <td>64091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>BHM00078583</td>\n",
       "      <td>17.5333</td>\n",
       "      <td>-88.3000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BELIZE/PHILLIP GOLDSTON INTL.</td>\n",
       "      <td>1980</td>\n",
       "      <td>2025</td>\n",
       "      <td>21481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>BRM00082022</td>\n",
       "      <td>2.8490</td>\n",
       "      <td>-60.6943</td>\n",
       "      <td>83.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOA VISTA (AERO)</td>\n",
       "      <td>1977</td>\n",
       "      <td>2025</td>\n",
       "      <td>11589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>BRM00082026</td>\n",
       "      <td>2.2200</td>\n",
       "      <td>-55.9300</td>\n",
       "      <td>325.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TIRIOS (AERO)</td>\n",
       "      <td>2006</td>\n",
       "      <td>2025</td>\n",
       "      <td>9440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  latitude  longitude  elevation state  \\\n",
       "193  BBM00078954   13.0716   -59.4922       56.6   NaN   \n",
       "200  BDM00078016   32.3669   -64.6772        4.0   NaN   \n",
       "224  BHM00078583   17.5333   -88.3000        5.0   NaN   \n",
       "258  BRM00082022    2.8490   -60.6943       83.5   NaN   \n",
       "259  BRM00082026    2.2200   -55.9300      325.0   NaN   \n",
       "\n",
       "                               name  fst_year  lst_year   nobs  \n",
       "193                  GRANTLEY ADAMS      1965      2025  31823  \n",
       "200  L F WADE INTERNATIONAL AIRPORT      1946      2025  64091  \n",
       "224   BELIZE/PHILLIP GOLDSTON INTL.      1980      2025  21481  \n",
       "258                BOA VISTA (AERO)      1977      2025  11589  \n",
       "259                   TIRIOS (AERO)      2006      2025   9440  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stations = pd.read_csv(STATION_LIST)\n",
    "df_stations = df_stations[df_stations['lst_year'] == 2025]\n",
    "df_stations = df_stations[df_stations['latitude'] > 0]\n",
    "df_stations = df_stations[df_stations['longitude'] < -30]\n",
    "df_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d05eba1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/usr/datalake/silver/igra/gph20s10k/BBM00078954-data-gph20s10k.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, station \u001b[38;5;129;01min\u001b[39;00m df_stations.iterrows():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mprocess_station\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstation\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mprocess_station\u001b[39m\u001b[34m(station_id)\u001b[39m\n\u001b[32m      2\u001b[39m model = AutoEncoder().cuda()\n\u001b[32m      3\u001b[39m train = olie_igra_trainer(IGRA_PATH, ARTIFACTS_PATH, station_id, model)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_transform_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m train.train_orch()\n\u001b[32m      7\u001b[39m train.save_weights()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36molie_igra_trainer.load_transform_dataset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_transform_dataset\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     X = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43migra_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstation_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m-data-gph20s10k.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# Remove irrelevant data\u001b[39;00m\n\u001b[32m     18\u001b[39m     X = X[X[\u001b[33m'\u001b[39m\u001b[33mhour\u001b[39m\u001b[33m'\u001b[39m] == \u001b[32m12\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oliev\\source\\repos\\olieigra\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oliev\\source\\repos\\olieigra\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oliev\\source\\repos\\olieigra\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oliev\\source\\repos\\olieigra\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oliev\\source\\repos\\olieigra\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/usr/datalake/silver/igra/gph20s10k/BBM00078954-data-gph20s10k.csv'"
     ]
    }
   ],
   "source": [
    "for _, station in df_stations.iterrows():\n",
    "    process_station(station['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c147a075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olieigra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
