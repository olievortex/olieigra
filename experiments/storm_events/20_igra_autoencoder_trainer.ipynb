{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33560cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Module, Sequential, Linear, Tanh, MSELoss\n",
    "\n",
    "IGRA_PATH = '/usr/datalake/silver/igra/gph20s10k'\n",
    "STATION_LIST = '/usr/datalake/silver/igra/doc/igra2-station-list.csv'\n",
    "ARTIFACTS_PATH = '/usr/datalake/silver/stormevents/artifacts/igra_storm_event_autoencoder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8256237",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Sequential(\n",
    "            Linear(105, 80),\n",
    "            Tanh(),\n",
    "            Linear(80, 60),\n",
    "            Tanh(),\n",
    "            Linear(60, 40),\n",
    "            Tanh(),\n",
    "            Linear(40, 20)\n",
    "        )\n",
    "\n",
    "        self.decoder = Sequential(\n",
    "            Linear(20, 40),\n",
    "            Tanh(),\n",
    "            Linear(40, 60),\n",
    "            Tanh(),\n",
    "            Linear(60, 80),\n",
    "            Tanh(),\n",
    "            Linear(80, 105)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b2073f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class olie_igra_trainer:\n",
    "    batch_size = 256\n",
    "    epochs = 1024\n",
    "    learning_rate = 0.005\n",
    "    learning_rate_gamma = 0.99\n",
    "    lambda_param = .0001\n",
    "\n",
    "    def __init__(self, igra_path: str, artifact_path: str, station_id: str, model):\n",
    "        self.igra_path = igra_path\n",
    "        self.station_id = station_id\n",
    "        self.artifact_path = artifact_path\n",
    "        self.model = model\n",
    "\n",
    "    def load_transform_dataset(self):\n",
    "        X = pd.read_csv(f'{self.igra_path}/{self.station_id}-data-gph20s10k.csv')\n",
    "\n",
    "        # Remove irrelevant data\n",
    "        X = X[X['hour'] == 12]\n",
    "        X = X.drop(['id', 'effective_date', 'hour', 'day_num', '0_gph',\n",
    "                    '1_gph', '2_gph', '3_gph', '4_gph', '5_gph',\n",
    "                    '6_gph', '7_gph', '8_gph', '9_gph', '10_gph',\n",
    "                    '11_gph', '12_gph', '13_gph', '14_gph', '15_gph',\n",
    "                    '16_gph', '17_gph', '18_gph', '19_gph', '20_gph'\n",
    "                    ], axis=1)\n",
    "        if X.shape[0] == 0:\n",
    "            return False\n",
    "        \n",
    "        # Scale the X dataset\n",
    "        ss = PowerTransformer()\n",
    "        X = ss.fit_transform(X)\n",
    "\n",
    "        # Save the transform\n",
    "        os.makedirs(self.artifact_path, exist_ok=True)\n",
    "        with open(f'{self.artifact_path}/{self.station_id}_scaler.pkl', 'wb') as f:\n",
    "            pickle.dump(ss, f)\n",
    "        \n",
    "        train, test = train_test_split(X, test_size=0.2)\n",
    "        self.x_train = torch.from_numpy(train).float().cuda()\n",
    "        self.x_test = torch.from_numpy(test).float().cuda()\n",
    "        self.n_batches = self.x_train.size()[0] // self.batch_size\n",
    "\n",
    "        print (f\"Station ID: {self.station_id}, Training size: {self.x_train.size()[0]:,}, Predict size: {self.x_test.size()[0]:,}, Feature count: {self.x_train.size()[1]}, Number of batches: {self.n_batches}\")\n",
    "\n",
    "        return True\n",
    "    \n",
    "    def train(self, inputs, labels) -> float:\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Calculate error\n",
    "        logits = self.model(inputs)\n",
    "        cost = self.loss_function(logits, labels)\n",
    "\n",
    "        # Back propagation\n",
    "        cost.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return float(cost.item())\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Calculate error\n",
    "        logits = self.model(inputs).clone().detach()\n",
    "\n",
    "        return logits\n",
    "    \n",
    "    def r2_score_manual(self, preds, target):\n",
    "        target_mean = torch.mean(target)\n",
    "        ss_tot = torch.sum((target - target_mean) ** 2) # Total sum of squares\n",
    "        ss_res = torch.sum((target - preds) ** 2)       # Residual sum of squares\n",
    "        r2 = 1 - (ss_res / ss_tot)\n",
    "        \n",
    "        return float(r2.item())\n",
    "    \n",
    "    def output_progress(self, epoch: int, cost: float, batches: float):\n",
    "        preds = self.predict(self.x_test)\n",
    "        acc = self.r2_score_manual(self.x_test, preds)\n",
    "        print(f\"Epoch: {epoch}, cost: {cost / batches:.4f}, acc: {acc:.3f}, lr: {self.scheduler.get_last_lr()[0]:.2e}\\r\", end=\"\")\n",
    "        \n",
    "    def train_orch(self):\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), self.learning_rate)\n",
    "        self.loss_function = MSELoss()\n",
    "        self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=self.learning_rate_gamma)\n",
    "    \n",
    "        for epoch in range(self.epochs):\n",
    "            cost = 0\n",
    "            batches = 0.\n",
    "            loader = DataLoader(dataset = self.x_train, batch_size = self.batch_size, shuffle = True)\n",
    "\n",
    "            for batch in loader:\n",
    "                cost += self.train(batch, batch)\n",
    "                batches += float(batch.size()[0]) / self.batch_size\n",
    "\n",
    "            self.scheduler.step()\n",
    "\n",
    "            if epoch % 32 == 0:\n",
    "                self.output_progress(epoch, cost, batches)\n",
    "        \n",
    "        self.output_progress(epoch, cost, batches)\n",
    "        print()\n",
    "\n",
    "    def save_weights(self):\n",
    "        torch.save(self.model.state_dict(), f'{self.artifact_path}/{self.station_id}_fnn.pt')\n",
    "\n",
    "    def exists_weights(self):\n",
    "        return os.path.exists(f'{self.artifact_path}/{self.station_id}_fnn.pt')\n",
    "\n",
    "    def dispose(self):\n",
    "        del self.x_train\n",
    "        del self.x_test\n",
    "        del self.optimizer\n",
    "        del self.loss_function\n",
    "        del self.scheduler\n",
    "        del self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "610544ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_station(station_id: str):\n",
    "    model = AutoEncoder().cuda()\n",
    "    train = olie_igra_trainer(IGRA_PATH, ARTIFACTS_PATH, station_id, model)\n",
    "\n",
    "    if train.exists_weights():\n",
    "        print(f\"Station {station_id} already processed\")\n",
    "        return\n",
    "\n",
    "    result = train.load_transform_dataset()\n",
    "    if not result:\n",
    "        print(f\"Station {station_id} has zero usable rows\")\n",
    "        return\n",
    "    \n",
    "    if train.x_train.size()[0] < train.batch_size:\n",
    "        print(f\"Station {station_id} has too few usable rows\")\n",
    "        return\n",
    "    \n",
    "    train.train_orch()\n",
    "    train.save_weights()\n",
    "    train.dispose()\n",
    "\n",
    "    del train\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d05eba1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station BBM00078954 already processed\n",
      "Station BDM00078016 has zero usable rows\n",
      "Station BHM00078583 already processed\n",
      "Station BRM00082022 has zero usable rows\n",
      "Station BRM00082026 has zero usable rows\n",
      "Station BRM00082099 has zero usable rows\n",
      "Station CAM00071043 has zero usable rows\n",
      "Station CAM00071081 has zero usable rows\n",
      "Station CAM00071082 has zero usable rows\n",
      "Station CAM00071109 has zero usable rows\n",
      "Station CAM00071119 has zero usable rows\n",
      "Station CAM00071603 has zero usable rows\n",
      "Station CAM00071701 has zero usable rows\n",
      "Station CAM00071722 has zero usable rows\n",
      "Station CAM00071802 has zero usable rows\n",
      "Station CAM00071811 has zero usable rows\n",
      "Station CAM00071815 has zero usable rows\n",
      "Station CAM00071816 has zero usable rows\n",
      "Station CAM00071823 has zero usable rows\n",
      "Station CAM00071843 has zero usable rows\n",
      "Station CAM00071845 has zero usable rows\n",
      "Station CAM00071867 has zero usable rows\n",
      "Station CAM00071906 has zero usable rows\n",
      "Station CAM00071907 has zero usable rows\n",
      "Station CAM00071908 has zero usable rows\n",
      "Station CAM00071909 has zero usable rows\n",
      "Station CAM00071913 has zero usable rows\n",
      "Station CAM00071917 has zero usable rows\n",
      "Station CAM00071924 has zero usable rows\n",
      "Station CAM00071925 has zero usable rows\n",
      "Station CAM00071926 has zero usable rows\n",
      "Station CAM00071934 has zero usable rows\n",
      "Station CAM00071945 has zero usable rows\n",
      "Station CAM00071957 has zero usable rows\n",
      "Station CAM00071964 has zero usable rows\n",
      "Station CAM00073033 has zero usable rows\n",
      "Station CAM00073111 has zero usable rows\n",
      "Station CJM00078384 already processed\n",
      "Station COM00080001 already processed\n",
      "Station COM00080028 has zero usable rows\n",
      "Station COM00080094 has zero usable rows\n",
      "Station COM00080222 has zero usable rows\n",
      "Station COM00080259 has zero usable rows\n",
      "Station DRM00078486 already processed\n",
      "Station FGM00081405 has zero usable rows\n",
      "Station GLM00004220 has zero usable rows\n",
      "Station GLM00004270 has zero usable rows\n",
      "Station GLM00004360 has zero usable rows\n",
      "Station GLM00004417 has zero usable rows\n",
      "Station GPM00078897 has zero usable rows\n",
      "Station JMM00078397 already processed\n",
      "Station MXM00076256 has zero usable rows\n",
      "Station MXM00076394 has zero usable rows\n",
      "Station MXM00076405 has zero usable rows\n",
      "Station MXM00076458 has zero usable rows\n",
      "Station MXM00076526 has zero usable rows\n",
      "Station MXM00076595 has zero usable rows\n",
      "Station MXM00076612 has zero usable rows\n",
      "Station MXM00076644 has zero usable rows\n",
      "Station MXM00076654 has zero usable rows\n",
      "Station MXM00076679 has zero usable rows\n",
      "Station MXM00076692 has zero usable rows\n",
      "Station MXM00076743 has zero usable rows\n",
      "Station MXM00076805 has zero usable rows\n",
      "Station MXM00076903 has zero usable rows\n",
      "Station NNM00078866 already processed\n",
      "Station PMM00078807 has zero usable rows\n",
      "Station RQM00078526 already processed\n",
      "Station TDM00078970 already processed\n",
      "Station UCM00078988 already processed\n",
      "Station USM00070026 already processed\n",
      "Station USM00070133 already processed\n",
      "Station USM00070200 already processed\n",
      "Station USM00070219 already processed\n",
      "Station USM00070231 already processed\n",
      "Station USM00070261 already processed\n",
      "Station USM00070273 already processed\n",
      "Station USM00070308 already processed\n",
      "Station USM00070316 already processed\n",
      "Station USM00070326 already processed\n",
      "Station USM00070350 already processed\n",
      "Station USM00070361 already processed\n",
      "Station USM00070398 already processed\n",
      "Station USM00072201 already processed\n",
      "Station USM00072202 already processed\n",
      "Station USM00072206 already processed\n",
      "Station USM00072208 already processed\n",
      "Station USM00072210 already processed\n",
      "Station USM00072215 already processed\n",
      "Station USM00072221 has zero usable rows\n",
      "Station USM00072230 already processed\n",
      "Station USM00072233 already processed\n",
      "Station USM00072235 already processed\n",
      "Station USM00072240 already processed\n",
      "Station USM00072248 already processed\n",
      "Station USM00072249 already processed\n",
      "Station USM00072250 already processed\n",
      "Station USM00072251 already processed\n",
      "Station USM00072261 already processed\n",
      "Station USM00072265 already processed\n",
      "Station USM00072274 already processed\n",
      "Station USM00072293 already processed\n",
      "Station USM00072305 already processed\n",
      "Station USM00072317 already processed\n",
      "Station USM00072318 already processed\n",
      "Station USM00072327 already processed\n",
      "Station USM00072340 already processed\n",
      "Station USM00072357 already processed\n",
      "Station USM00072363 already processed\n",
      "Station USM00072364 already processed\n",
      "Station USM00072365 already processed\n",
      "Station USM00072376 already processed\n",
      "Station USM00072381 already processed\n",
      "Station USM00072388 already processed\n",
      "Station ID: USM00072391, Training size: 149, Predict size: 38, Feature count: 105, Number of batches: 0\n",
      "Station USM00072391 has too few usable rows\n",
      "Station USM00072393 has zero usable rows\n",
      "Station USM00072402 already processed\n",
      "Station USM00072403 already processed\n",
      "Station USM00072426 already processed\n",
      "Station USM00072440 already processed\n",
      "Station USM00072451 already processed\n",
      "Station USM00072456 already processed\n",
      "Station USM00072476 already processed\n",
      "Station USM00072489 already processed\n",
      "Station USM00072493 already processed\n",
      "Station USM00072501 already processed\n",
      "Station USM00072518 already processed\n",
      "Station USM00072520 already processed\n",
      "Station USM00072528 already processed\n",
      "Station USM00072558 already processed\n",
      "Station USM00072562 already processed\n",
      "Station USM00072572 already processed\n",
      "Station USM00072582 already processed\n",
      "Station USM00072597 already processed\n",
      "Station USM00072632 already processed\n",
      "Station USM00072634 already processed\n",
      "Station USM00072645 already processed\n",
      "Station USM00072649 already processed\n",
      "Station USM00072659 already processed\n",
      "Station USM00072662 already processed\n",
      "Station USM00072672 already processed\n",
      "Station USM00072681 already processed\n",
      "Station USM00072694 already processed\n",
      "Station USM00072712 already processed\n",
      "Station USM00072747 already processed\n",
      "Station USM00072764 already processed\n",
      "Station USM00072768 already processed\n",
      "Station USM00072776 already processed\n",
      "Station USM00072786 already processed\n",
      "Station USM00072797 already processed\n",
      "Station USM00074003 has zero usable rows\n",
      "Station USM00074004 has zero usable rows\n",
      "Station USM00074005 has zero usable rows\n",
      "Station USM00074389 already processed\n",
      "Station USM00074455 already processed\n",
      "Station USM00074560 already processed\n",
      "Station ID: USM00074612, Training size: 140, Predict size: 35, Feature count: 105, Number of batches: 0\n",
      "Station USM00074612 has too few usable rows\n",
      "Station USM00074626 has zero usable rows\n",
      "Station USM00074646 has zero usable rows\n",
      "Station USM00074794 has zero usable rows\n",
      "Station USM00091165 already processed\n",
      "Station USM00091285 already processed\n"
     ]
    }
   ],
   "source": [
    "for filepath in glob.glob(f'{IGRA_PATH}/*-data-gph20s10k.csv'):\n",
    "    filename = Path(filepath).name\n",
    "    station_id = filename.split('-')[0]\n",
    "\n",
    "    process_station(station_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c147a075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olieigra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
