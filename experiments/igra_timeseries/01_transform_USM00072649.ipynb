{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from datetime import datetime\n",
    "# import numpy as np\n",
    "import olieigra\n",
    "\n",
    "BRONZE_DATA_POR_PATH = '/usr/datalake/bronze/igra/data-por'\n",
    "SILVER_TIMESERIES_PATH = '/usr/datalake/silver/igra/timeseries'\n",
    "STATION_ID = 'USM00072649'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the destination path exists\n",
    "os.makedirs(SILVER_TIMESERIES_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OlieTimeSeries(olieigra.Callbacks):\n",
    "    gph_top = 10000\n",
    "    min_usable = 20\n",
    "\n",
    "    def __init__(self, station_id: str, dst_path: str, min_effective_date: datetime):\n",
    "        super().__init__()\n",
    "        self.station_id = station_id\n",
    "        self.dst_path = dst_path\n",
    "        self.filename = ''\n",
    "        self.filtered = 0\n",
    "        self.rejected = 0\n",
    "        self.writer = None\n",
    "        self.min_effective_date = min_effective_date\n",
    "        self.hout = ''\n",
    "\n",
    "\n",
    "    def start_file(self, filename: str) -> bool:\n",
    "        \"\"\"Decide if we want to process the file. If so, reset state and start writing to a\n",
    "        temporary file.\"\"\"\n",
    "\n",
    "        # An IGRA2 file should end with -data.txt\n",
    "        if not filename.endswith('-data.txt'):\n",
    "            # print(f'Skipping {filename}. Not sure what to do with it.')\n",
    "            return False\n",
    "        \n",
    "        # Only process the file for the station we care about\n",
    "        if not filename.startswith(self.station_id):\n",
    "            # print(f'Skipping {filename}. Not the target file.')\n",
    "            return False\n",
    "\n",
    "        # Set the desired destination filename\n",
    "        dst_filename = f'{self.dst_path}/{filename}'\n",
    "        dst_filename = dst_filename.replace(\"-data.txt\", \"-data-timeseries.csv\")\n",
    "\n",
    "        # Skip this file if it has already been processed\n",
    "        if os.path.exists(dst_filename):\n",
    "            print(f'Skipping {filename}. Destination file already exists.')\n",
    "            return False\n",
    "\n",
    "        # If we got here, we are going to process the file\n",
    "        print(f'Processing {filename}.')\n",
    "\n",
    "        # Write to a temp file\n",
    "        self.filename = dst_filename.replace('.csv', '.partial.csv')\n",
    "        self.writer = open(self.filename, 'w', encoding='UTF-8')\n",
    "        self.hout = ''\n",
    "\n",
    "        # Reset the record counts\n",
    "        self.filtered = 0\n",
    "        self.rejected = 0\n",
    "\n",
    "        # Write the header row\n",
    "        self.writer.write(f\"effective_date,hour,day_num,gph,pres,temp,dp,u,v\\n\")\n",
    "\n",
    "        # Tell olieigra to continue processing\n",
    "        return True\n",
    "\n",
    "\n",
    "    def finish_file(self, headers: int, rows: int):\n",
    "        \"\"\"Callback for when processing is complete\"\"\"\n",
    "\n",
    "        # Flush and close the temp file\n",
    "        self.writer.close()\n",
    "        self.writer = None\n",
    "\n",
    "        # Rename it to the final filename\n",
    "        dst_renamed = self.filename.replace('.partial.csv', '.csv')\n",
    "        os.rename(self.filename, dst_renamed)\n",
    "\n",
    "        # Calculate the number of records written\n",
    "        loaded = headers - self.filtered - self.rejected\n",
    "\n",
    "        print(f\" Read {headers} headers, {rows} lines. Filtered {self.filtered}. \" +\n",
    "              f\"Rejected {self.rejected}. Wrote {loaded} records.\")\n",
    "\n",
    "\n",
    "    def parse_header(self, header: olieigra.HeaderModel):\n",
    "        \"\"\"Transform the header record\"\"\"\n",
    "\n",
    "        # Combine seperate fields into a datetime\n",
    "        effective_date = datetime(header.year, header.month, header.day)\n",
    "\n",
    "        # Filter out the observations that are too old\n",
    "        if effective_date < self.min_effective_date:\n",
    "            self.filtered += 1\n",
    "            return False\n",
    "\n",
    "        # We need some number that is analogous to the amount of sunlight and the season\n",
    "        day_num = -math.cos(math.radians(effective_date.timetuple().tm_yday))\n",
    "\n",
    "        # The observation may be rejected due to body data issues. Save the header values to\n",
    "        # a variable for now. The parse_body will write it to the file, if appropriate.\n",
    "        self.hout = f'{effective_date:%Y-%m-%d},{header.hour},{day_num:.2f}'\n",
    "\n",
    "        # Continue the processing\n",
    "        return True\n",
    "\n",
    "\n",
    "    def parse_body(self, body: list[olieigra.BodyModel]):\n",
    "        \"\"\"Perform some analytics on the body\"\"\"\n",
    "\n",
    "        # Remove non-pressure records and records with bad data\n",
    "        filtered = self.filter_body(body)\n",
    "\n",
    "        # If the obs failed validation checks, skip it\n",
    "        if len(filtered) == 0:\n",
    "            self.rejected += 1\n",
    "            return\n",
    "\n",
    "        # Spew the records\n",
    "        for record in filtered:\n",
    "            # Write the record\n",
    "            self.writer.write(f'{self.hout},{record[0]},{record[1]},{record[2]},{record[3]},{record[4]},{record[5]}\\n')\n",
    "\n",
    "\n",
    "    def filter_body(self, body: list[olieigra.BodyModel]) -> list[float]:\n",
    "        \"\"\"Filter out bad data\"\"\"\n",
    "        result = []\n",
    "        usable_count = 0\n",
    "        surface_nan = 1\n",
    "        last_gph = -1\n",
    "\n",
    "        # Iterate over every body record\n",
    "        for item in body:\n",
    "            # If we have at least one record over 10k in height, we have enough data to interpolate\n",
    "            if last_gph >= 10000:\n",
    "                break\n",
    "\n",
    "            # Skip non-pressure records\n",
    "            if item.type[0] == '3':\n",
    "                continue\n",
    "\n",
    "            # Skip records with bad or missing data\n",
    "            if math.isnan(item.dpdp) | math.isnan(item.rh) | math.isnan(item.temp) | \\\n",
    "                    math.isnan(item.wdir) | math.isnan(item.wspd) | math.isnan(item.gph):\n",
    "                continue\n",
    "\n",
    "            # If we got here, the record passed validation. Add it to the results.\n",
    "            result.append(self.transform_body(item))\n",
    "\n",
    "            # Clear the flag if we find a valid surface sample\n",
    "            if item.type == '21':\n",
    "                surface_nan = 0\n",
    "\n",
    "            # Update tracking variables\n",
    "            last_gph = item.gph\n",
    "            usable_count += 1\n",
    "\n",
    "        # Final validation\n",
    "        if usable_count >= self.min_usable and surface_nan == 0 and last_gph >= self.gph_top:\n",
    "            # Reject the entire obs if we don't have 20 valid samples, there is \n",
    "            # not a valid surface sample, or if the balloon didn't make it to 10k\n",
    "            # above the surface.\n",
    "            return result\n",
    "        else:\n",
    "            # Passed validation, return the results\n",
    "            return []\n",
    "\n",
    "\n",
    "    def transform_body(self, item: olieigra.BodyModel) -> list[float]:\n",
    "        \"\"\"Transform the body\"\"\"\n",
    "\n",
    "        gph = item.gph\n",
    "        pres = item.pres / 100.0\n",
    "        temp = item.temp / 10.0\n",
    "        dp = (item.temp - item.dpdp) / 10.0\n",
    "\n",
    "        # Convert wind from degrees/m^s to u,v\n",
    "        wrad = math.radians(item.wdir)\n",
    "        u = round(-item.wspd * math.sin(wrad) / 10.0, 1)\n",
    "        v = round(-item.wspd * math.cos(wrad) / 10.0, 1)\n",
    "\n",
    "        return [gph, pres, temp, dp, u, v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing USM00072649-data.txt.\n",
      " Read 28130 headers, 4133846 lines. Filtered 5951. Rejected 2828. Wrote 19351 records.\n"
     ]
    }
   ],
   "source": [
    "callbacks = OlieTimeSeries(STATION_ID, SILVER_TIMESERIES_PATH, datetime(1990, 1, 1))\n",
    "reader = olieigra.Reader(callbacks=callbacks)\n",
    "crawler = olieigra.Crawler(reader=reader)\n",
    "\n",
    "crawler.crawl(BRONZE_DATA_POR_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olieigra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
